#+STARTUP: overview indent inlineimages logdrawer
#+TITLE:  Autotuning Methods
#+AUTHOR:      Pedro Bruel
#+LANGUAGE:    en
#+TAGS: noexport(n) Stats(S)
#+TAGS: Teaching(T) R(R) OrgMode(O) Python(P)
#+TAGS: Book(b) DOE(D) Code(C) NODAL(N) FPGA(F) Autotuning(A) Arnaud(r)
#+TAGS: ExportableReports(E)
#+TAGS: FAPESP(f)
#+TAGS: DataVis(v) PaperReview(W)
#+EXPORT_SELECT_TAGS: Blog
#+OPTIONS:   H:3 num:t toc:nil \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+OPTIONS:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+COLUMNS: %25ITEM %TODO %3PRIORITY %TAGS
#+SEQ_TODO: TODO(t!) STARTED(s!) WAITING(w@) APPT(a!) | DONE(d!) CANCELLED(c!) DEFERRED(f!)

#+LATEX_CLASS: book
#+LATEX_CLASS_OPTIONS: [12pt,twoside,a4paper]
#+LATEX_HEADER: \usepackage[a4paper]{geometry}
#+LATEX_HEADER: \geometry{
#+LATEX_HEADER:   %top=32mm,
#+LATEX_HEADER:   %bottom=28mm,
#+LATEX_HEADER:   %left=24mm,
#+LATEX_HEADER:   %right=34mm,
#+LATEX_HEADER:   textwidth=152mm, % 210-24-34
#+LATEX_HEADER:   textheight=237mm, % 297-32-28
#+LATEX_HEADER:   vmarginratio=8:7, % 32:28
#+LATEX_HEADER:   hmarginratio=12:17, % 24:34
#+LATEX_HEADER:   % Com geometry, esta medida não é tão relevante; basta garantir que ela
#+LATEX_HEADER:   % seja menor que "top" e que o texto do cabeçalho caiba nela.
#+LATEX_HEADER:   headheight=25.4mm,
#+LATEX_HEADER:   % distância entre o início do texto principal e a base do cabeçalho;
#+LATEX_HEADER:   % ou seja, o cabeçalho "invade" a margem superior nessa medida. Essa
#+LATEX_HEADER:   % é a medida que determina a posição do cabeçalho
#+LATEX_HEADER:   headsep=11mm,
#+LATEX_HEADER:   footskip=10mm,
#+LATEX_HEADER:   marginpar=20mm,
#+LATEX_HEADER:   marginparsep=5mm,
#+LATEX_HEADER: }
#+LATEX_HEADER: \usepackage{setspace}
#+LATEX_HEADER: \usepackage{amsmath,amsfonts,amssymb,amsthm}
#+LATEX_HEADER: \usepackage[dvipsnames]{xcolor}
#+LATEX_HEADER: \usepackage{sourcecodepro}
#+LATEX_HEADER: \usepackage{forest}
#+LATEX_HEADER: \usepackage{titling}
#+LATEX_HEADER: \usepackage{rotating}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{array}
#+LATEX_HEADER: \usepackage{colortbl}
#+LATEX_HEADER: \usepackage{listings}
#+LATEX_HEADER: \usepackage{tikz}
#+LATEX_HEADER: \usepackage{tikz-qtree}
#+LATEX_HEADER: \usepackage{algpseudocode}
#+LATEX_HEADER: \usepackage{algorithm}
#+LATEX_HEADER: \usepackage{graphicx}
#+LATEX_HEADER: \usepackage[english]{babel}
#+LATEX_HEADER: \usepackage[scale=2]{ccicons}
#+LATEX_HEADER: \usepackage{hyperref}
#+LATEX_HEADER: \usepackage{relsize}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{bm}
#+LATEX_HEADER: \usepackage{amsfonts}
#+LATEX_HEADER: \usepackage{wasysym}
#+LATEX_HEADER: \usepackage{float}
#+LATEX_HEADER: \usepackage{ragged2e}
#+LATEX_HEADER: \usepackage{textcomp}
#+LATEX_HEADER: \usepackage{pgfplots}
#+LATEX_HEADER: \usepackage{todonotes}
#+LATEX_HEADER: \usepgfplotslibrary{dateplot}
#+LATEX_HEADER: \lstdefinelanguage{Julia}%
#+LATEX_HEADER:   {morekeywords={abstract,struct,break,case,catch,const,continue,do,else,elseif,%
#+LATEX_HEADER:       end,export,false,for,function,immutable,mutable,using,import,importall,if,in,%
#+LATEX_HEADER:       macro,module,quote,return,switch,true,try,catch,type,typealias,%
#+LATEX_HEADER:       while,<:,+,-,::,/},%
#+LATEX_HEADER:    sensitive=true,%
#+LATEX_HEADER:    alsoother={$},%
#+LATEX_HEADER:    morecomment=[l]\#,%
#+LATEX_HEADER:    morecomment=[n]{\#=}{=\#},%
#+LATEX_HEADER:    morestring=[s]{"}{"},%
#+LATEX_HEADER:    morestring=[m]{'}{'},%
#+LATEX_HEADER: }[keywords,comments,strings]%
#+LATEX_HEADER: \lstset{ %
#+LATEX_HEADER:   backgroundcolor={},
#+LATEX_HEADER:   basicstyle=\ttfamily\scriptsize,
#+LATEX_HEADER:   breakatwhitespace=true,
#+LATEX_HEADER:   breaklines=true,
#+LATEX_HEADER:   captionpos=n,
# #+LATEX_HEADER:   escapeinside={\%*}{*)},
#+LATEX_HEADER:   extendedchars=true,
#+LATEX_HEADER:   frame=n,
#+LATEX_HEADER:   language=R,
#+LATEX_HEADER:   rulecolor=\color{black},
#+LATEX_HEADER:   showspaces=false,
#+LATEX_HEADER:   showstringspaces=false,
#+LATEX_HEADER:   showtabs=false,
#+LATEX_HEADER:   stepnumber=2,
#+LATEX_HEADER:   stringstyle=\color{gray},
#+LATEX_HEADER:   tabsize=2,
#+LATEX_HEADER: }
#+LATEX_HEADER: \renewcommand*{\UrlFont}{\ttfamily\smaller\relax}
#+LATEX_HEADER: \singlespacing

* Thesis Drafts                                                    :noexport:
** Structure Drafts
1. Introduction
   1. Autotuning
      1. Algorithm Selection Problem?
   2. Overview of Autotuning Methods (taxonomy/decision tree)
   3. Search Heuristics
      - Introduction
      - OpenTuner
      - Autotuning GPU compiler parameters
      - Autotuning High Level Synthesis for FPGAs
   4. Statistical Learning
      - Parametric, nonparametric
   5. Related Work
      - Literature Review
2. Design of Experiments
   1. Introduction
      1. Linear Regression
   2. Screening
      1. Main effects
      2. Example with CUDA flags
   3. Factorial Designs
      1. Example?
   4. Optimal Design
      1. Properties of the BLUE, Information Matrix
      2. Variance-optimizing criteria
      3. Example on Laplacian GPU
   5. Autotuning SPAPT Kernels
      - Mixing factor types
      - Sampling with Constraints
      - Heteroscedasticity
3. Gaussian Process Regression
   1. Introduction
      1. Bayesian Linear Model (Rasmussen's Book)
      2. EGO
   2. Revisiting SPAPT kernels
   3. Quantization for Deep Neural Networks
4. Conclusion
   - Expressing structure with kernels? (Duvenaud's thesis)
   - Performance of the Federov Algorithm for D-Optimal design construction?
*** Structure Draft
- Course on performance optimization for HPC, and why it's hard
- Difficulty to optimize programs comes from complexity in:
  - Computer architecture
    - Pursuit of doubling performance, fitting more transistors,
      (Moore's Law), and the end of frequency and power
      scaling (Dennard's),
      mean that we need parallel architectures, which are more complex
  - Software
    - Parallel architectures are harder to program efficiently
** Underlying Hypotheses of Autotuning Methods
:PROPERTIES:
:EXPORT_FILE_NAME: hipotheses.pdf
:END:
*** Introduction                                                 :noexport:
Given  a program  with $X  \in \mathcal{X}$  configurable parameters,  we want  to
choose the best parameter values according  to a performance metric given by the
function  $f(X)$.   Autotuning methods  attempt  find  the $X_{*}$  that  minimizes
$f(\cdot)$.   Despite  their different  approaches,  autotuning  methods share  some
common hypotheses:

- There is no knowledge about the global optimal configuration
- There could be some problem-specific knowledge to exploit
- Measuring the effects of a choice of parameter values is possible but costly

Each  autotuning method  has  assumptions that  justify  its implementation  and
usage. Some of  these hypotheses are explicit,  such as the ones  that come from
the  linear model.   Others are  implicit,  such as  the ones  that support  the
implementation and the justification of optimization heuristics.
*** Overview of Autotuning Methods
:PROPERTIES:
:EXPORT_TITLE:
:EXPORT_FILE_NAME: tree.pdf
:END:
#+begin_export latex
\begin{sidewaysfigure}[t]
  \centering
  \resizebox{\textwidth}{!}{%
    \begin{forest}
      for tree={%
        anchor = north,
        align = center,
        l sep+=1em
      },
      [{Minimize $f: \mathcal{X} \mapsto \mathbb{R}$,\\$Y = f(X = (x_1,\dots,x_k) \in \mathcal{X}) + \varepsilon$},
        draw,
        [{Constructs surrogate estimate $\hat{f}(\cdot, \theta(X))$?},
          draw,
          color = NavyBlue
          [{Search Heuristics},
            draw,
            color = BurntOrange,
            edge label = {node[midway, fill=white, font = \scriptsize]{No}}
            [{\textbf{Random} \textbf{Sampling}}, draw]
            [{Reachable Optima},
              draw,
              color = BurntOrange
              [{Strong $corr(f(X),f(X^{\prime}))$,\\for close $X,X^{\prime}$},
                draw,
                color = BurntOrange
                [{Strong $corr(f(X),d(X,X_{*}))$?},
                  draw,
                  color = NavyBlue
                  [{More Global},
                    draw,
                    color = BurntOrange,
                    edge label = {node[midway, fill=white, font = \scriptsize]{No}}
                    [{Introduce a \textit{population} of $X$\\\textbf{Genetic} \textbf{Algorithms}}, draw]
                    [, phantom]]
                  [{More Local},
                    draw,
                    color = BurntOrange,
                    edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
                    [, phantom]
                    [{High local optima density?},
                      draw,
                      color = NavyBlue
                      [{Exploit Steepest Descent},
                        draw,
                        color = BurntOrange,
                        edge label = {node[midway, fill=white, font = \scriptsize]{No}}
                        [{In a neighbourhood:\\\textbf{Greedy} \textbf{Search}}, draw]
                        [{Estimate $f^{\prime}(X)$\\\textbf{Gradient} \textbf{Descent}}, draw]]
                      [{Allows\\exploration},
                        draw,
                        color = BurntOrange,
                        edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
                        [{Allow worse $f(X)$\\\textbf{Simulated} \textbf{Annealing}}, draw]
                        [{Avoid recent $X$\\\textbf{Tabu}\textbf{Search}}, draw]]]]]
                [,phantom]]
              [,phantom]]]
          [{Statistical Learning},
            draw,
            color = BurntOrange,
            edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
            [{Parametric Learning},
              draw,
              color = BurntOrange
              [{$\forall{}i: x_i \in X$ is discrete\\$\hat{f}(X) \approx f_1(x_1) + \dots + f_k(x_k)$},
                draw,
                color = BurntOrange
                [{\textbf{Independent Bandits}\\for each $x_i$:\textbf{UCB},\textbf{EXP3},$\dots$}, draw]
                [, phantom]]
              [{Linear Model\\$\hat{f} = \mathcal{M}(X)\theta{}(X) + \varepsilon$},
                draw,
                color = BurntOrange
                [, phantom]
                [{Check for model adequacy?},
                  draw,
                  alias = adequacy,
                  color = NavyBlue
                  [{Consider interactions?\\{$\exists x_i \neq x_j:\; \theta(x_ix_j) \neq 0$}},
                    draw,
                    alias = interactions,
                    color = NavyBlue,
                    edge label = {node[midway, fill=white, font = \scriptsize]{No}}
                    [{$\forall x_i \in X: x_i \in \{-1, 1\}$\\\textbf{Screening} \textbf{Designs}},
                      edge label = {node[midway, fill=white, font = \scriptsize]{No}},
                      draw
                      [, phantom]
                      [{Select $\hat{X}_{*}$, reduce dimension of $\mathcal{X}$},
                        edge = {-stealth, ForestGreen, semithick},
                        edge label = {node[midway, fill=white, font = \scriptsize]{Exploit}},
                        draw,
                        alias = estimate,
                        color = ForestGreen]]
                    [{\textbf{Optimal} \textbf{Design}},
                      draw,
                      alias = optimal,
                      edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}]]
                  [, phantom]
                  [, phantom]
                  [, phantom]
                  [, phantom]
                  [, phantom]
                  [, phantom]
                  [{\textbf{Space-filling} \textbf{Designs}},
                    draw,
                    edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
                    [, phantom]
                    [{Model selection},
                      edge = {-stealth, ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Explore}},
                      draw,
                      alias = selection,
                      color = ForestGreen]]]]]
            [{Nonparametric Learning},
              draw,
              color = BurntOrange
              [{Splitting rules on X\\\textbf{Decision} \textbf{Trees}},
                  draw
                  [, phantom]
                  [{Estimate $\hat{f}(\cdot)$ and $uncertainty(\hat{f}(\cdot))$},
                    edge = {-stealth, ForestGreen, semithick},
                    draw,
                    alias = uncertainty,
                    color = ForestGreen
                    [{Minimize $uncertainty(\hat{f}(X))$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Explore}},
                      draw,
                      color = ForestGreen]
                    [{Minimize $\hat{f}(X)$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Exploit}},
                      draw,
                      color = ForestGreen]
                    [{Minimize $\hat{f}(X) - uncertainty(\hat{f}(X))$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Exploit$+$Explore}},
                      draw,
                      color = ForestGreen]]]
              [{\textbf{Gaussian} \textbf{Process Regression}},
                alias = gaussian,
                draw]
              [{\textbf{Neural} \textbf{Networks}}, draw]]]]]
      \draw [-stealth, semithick, ForestGreen](selection) to [bend left=27] node[near start, fill=white, font = \scriptsize] {Exploit} (adequacy.south);
      \draw [-stealth, semithick, ForestGreen](estimate.east) to [bend right=37] node[near start, fill=white, font = \scriptsize] {Explore} (adequacy.south) ;
      \draw [-stealth, semithick, ForestGreen](gaussian) to (uncertainty);
      \draw [-stealth, semithick, ForestGreen](optimal) to node[midway, fill=white, font = \scriptsize] {Exploit} (estimate) ;
    \end{forest}
  }
  \caption{A high-level view of autotuning methods, where \textcolor{NavyBlue}{\textbf{blue}} boxes
    denote branching questions, \textcolor{BurntOrange}{\textbf{orange}} boxes
    denote key hypotheses, \textcolor{ForestGreen}{\textbf{green}} boxes
    denote algorithm choices, and \textbf{bold} boxes denote methods.}
\end{sidewaysfigure}
#+end_export

*** Previous Attempts                                            :noexport:
#+begin_export latex
\forestset{linebreaks/.style={for tree={align = center}}}
\begin{sidewaysfigure}
  \resizebox{\textwidth}{!}{%
    \begin{forest}
      linebreaks
      [{Minimize $f: \mathcal{X} \mapsto \mathbb{R}$,\\ $Y = f(X = (x_1,\dots,x_k) \in \mathcal{X}) + \varepsilon$}
        [{Does not construct\\estimate $Y = \hat{f}(\cdot, \theta{}(X))$}
          [{Reachable\\optima}
            [{Strong $corr(f(X),f(X^{\prime}))$,\\for close $X,X^{\prime}$}
              [{Strong\\$corr(f(X),d(X,X_{*}))$}
                [{Low local\\optima density}
                  [{\textbf{Greedy}\\\textbf{Search}}, draw]
                  [{Estimate $f^{\prime}(X)$}
                    [{\textbf{Gradient}\\\textbf{Descent}}, draw]]]
                [{Introduce a ``population''\\$\mathbf{X} = (X_1,\dots,X_n)$}
                  [{Combination, mutation,\\within $\mathbf{X}$}
                    [{\textbf{Genetic}\\\textbf{Algorithms}}, draw]]
                  [{\textbf{Ant}\\\textbf{Colony}}, draw]]]
              [{Weaker\\$corr(f(X),d(X,X_{*}))$}
                [{Accept\\worst $f(X)$}
                  [{\textbf{Simulated}\\\textbf{Annealing}}, draw]]
                [{Avoid\\recent $X$}
                  [{\textbf{Tabu}\\\textbf{Search}}, draw]]]]]
          [{\textbf{Random}\\\textbf{Sampling}}, draw]]
        [{Constructs surrogate\\estimate $\hat{f}(\cdot, \theta(X))$}
          [{Parametric\\Learning}
            [{$\hat{f}(X) \approx f_1(X_1) + \dots + f_k(X_k)$}
              [{\textbf{Independent}\\\textbf{Bandit}}, draw]]
            [{$\hat{f}(X) = \mathcal{B}(logit(\mathcal{M}(X)\theta(X) + \varepsilon))$}
              [{\textbf{Logistic}\\\textbf{Regression}}, draw]]
            [{$\hat{f}(X) = \mathcal{M}(X)\theta(X) + \varepsilon$}
              [{\textbf{Linear}\\\textbf{Regression}}, draw]
              [{Measure\\properties of $X$}
                [{Independance\\of effects}
                  [{\textbf{Screening}}, draw]]
                [{Homoscedasticity of $\varepsilon$}
                  [{\textbf{Optimal}\\\textbf{Design}}, draw]]]]]
          [{Nonparametric\\Learning}
            [{Splitting\\rules on $X$}
              [{\textbf{Decision}\\\textbf{Trees}}, draw]]
            [{$\hat{f} = \mathcal{GP}(X; \mathcal{K})$}
              [{\textbf{Gaussian}\\\textbf{Process Regression}}, draw]]
            [{\textbf{Neural}\\\textbf{Networks}}, draw]
            [{\textbf{Multi-armed}\\\textbf{Bandit (?)}}, draw]]]]
    \end{forest}
  }
  \caption{Some hypothesis of some autotuning methods}
\end{sidewaysfigure}

#+end_export

#+begin_export latex
\newcommand{\tabitem}{~~\llap{\textbullet}~~}

\begin{table}[ht]
  \center
  \begin{tabular}{@{}p{0.3\textwidth}p{0.5\textwidth}@{}}
    \toprule
    Method &  Hypotheses \\ \midrule
    Metaheuristics & \tabitem There are similarities between natural fenomena and the target problem \\
    & \tabitem Gradual changes in configurations produce gradual changes in performance \\
    & \tabitem The optimal configuration is ``reachable'', by small changes, from non-optimal configurations  \\
    \addlinespace \\
    Machine Learning & \tabitem As more samples are obtained, decreases in ``out-of-sample error'' imply decreases ``in-sample error'' \\
    & \tabitem \textbf{TODO} What are the classes of models? \\
    \addlinespace \\
    Design of Experiments & \tabitem There is ``exploitable search space structure''\\
    & \tabitem Linear model: Response $\bm{Y}$ is an ``unobservable function'' of parameters $\bm{X}$: \\
    & \hspace{0.15\textwidth} $f(\bm{X}) = \bm{Y} = \bm{X\beta} + \bm{\varepsilon}$ \\
    & \tabitem Optimal Design: Variance of estimator $\hat{\bm{\beta}}$ is proportional to $\bm{X}$: \\
    & \hspace{0.15\textwidth} $\bm{\hat{\beta}} = \left(\bm{X}^{\intercal}\bm{X}\right)^{-1}\bm{X}^{\intercal}\bm{Y}$ \\
    \addlinespace \\
    Gaussian Process Regression & \tabitem Response $\bm{Y}$ is a sample from a multidimensional Gaussian distribution, with mean $m(\bf{X})$ and variance $k(\bm{X}, \bm{X}^{\intercal})$: \\
    & \hspace{0.1\textwidth} $\bm{Y} = f(\bm{X}) \sim \mathcal{N}(m(\bm{X}), k(\bm{X}, \bm{X}^{\intercal}))$ \\
    & \tabitem Predictions $\bm{Y_{*}}$ can be made conditioning distribution to observed data\\ \bottomrule
  \end{tabular}%
\end{table}
#+end_export

#+begin_export latex
\resizebox{!}{\textheight}{%
  \begin{tikzpicture}[rotate = -90]
    \begin{scope}
      \tikzset{every tree node/.style = {align = center}}
      \tikzset{level 1+/.style={level distance = 40pt}}
      \Tree [.\node(n0){Minimize $f: X \mapsto \mathbb{R}$ \\ $f(X) = f^{*}(X) + \varepsilon = m$};
        [.{Does not construct \\ estimate $\hat{f}(X; \theta)$}
          [.{Reachability of \\ optima}
            [.{\textbf{Greedy} \\ \textbf{Search}} ]
            [.{$d(x_i, x_j) \to 0$ $\implies$ \\ $d(f(x_i), f(x_j)) \to 0$}
              [.{Abundance of \\ local optima}
                [.{\textbf{Simulated} \\ \textbf{Annealing}} ]]
              [.{Closeness of a \\ ``population'' of $X$}
                [.{\textbf{Genetic} \\ \textbf{Algorithms}} ]]]]
          [.{\textbf{Random} \\ \textbf{Sampling}} ] ]
        [.\node(r1){Constructs surrogate \\ estimate $\hat{f}(X; \theta)$};
          [.{Explicit, variable \\ models of $\theta$}
            [.{$\hat{f} = M(X)\theta + \varepsilon$}
              [.{Independance \\ of effects}
                [.{\textbf{Screening}} ] ]
              [.{Homoscedasticity}
                [.{\textbf{Optimal} \\ \textbf{Design}} ] ] ] ]
          [.{Implicit, fixed \\ models of $\theta$}
            [.{\textbf{Neural Networks}} ] ]
          [.{Samples \\ functions}
            [.{$\hat{f} = \mathcal{GP}(X; \theta, \mathcal{K})$}
              [.{\textbf{Gaussian Process} \\ \textbf{Regression}} ] ] ] ] ]
    \end{scope}
    % \begin{scope}[thick]
    %   \draw [color = orange] (n0) to [bend left = 2] (r1);
    %   \draw [color = green] (n0) to [bend right = 2] (r1);
    % \end{scope}
  \end{tikzpicture}
}
#+end_export
** Application to the Microsoft Latin America PhD Award
*** Search Heuristics and Statistical Learning methods for Autotuning HPC Programs
:PROPERTIES:
:EXPORT_DATE:
:EXPORT_TITLE: @@latex: Search Heuristics and Statistical Learning \\ Methods for Program Autotuning@@
:EXPORT_FILE_NAME: application.pdf
:EXPORT_AUTHOR: Pedro Bruel
:END:

#+latex: \vspace{-4em}

High Performance Computing  has been a cornerstone of  collective scientific and
industrial progress  for at least  five decades.   Paying the cost  of increased
complexity,  software and  hardware  engineering advances  continue to  overcome
several challenges on the way of the sustained performance improvements observed
during the last  fifty years.  This mounting complexity means  that reaching the
advertised hardware  performance for  a given program  requires not  only expert
knowledge  of a  given hardware  architecture, but  also mastery  of programming
models  and  languages for  parallel  and  distributed  computing.

If we state performance optimization problems as /search/ or /learning/ problems, by
converting implementation  and configuration  choices to /parameters/  which might
affect  performance,  we  can  draw   and  adapt  proven  methods  from  search,
mathematical  optimization and  statistics. The  effectiveness of  these adapted
methods  on autotuning  problems varies  greatly,  and hinges  on practical  and
mathematical properties of the problem and the corresponding /search space/.

When  adapting methods  for autotuning,  we must  face challenges  emerging from
practical properties  such as restricted  time and cost budgets,  constraints on
feasible  parameter values,  and the  need to  mix /categorical/,  /continuous/, and
/discrete/ parameters. To achieve useful results, we must also choose methods that
make hypotheses compatible with problem search  spaces, such as the existence of
discoverable,  or at  least  exploitable, relationships  between parameters  and
performance.   Choosing  an autotuning  method  requires  determining a  balance
between the exploration of a problem, when we would seek to discover and explain
relationships between  parameters and performance,  and the exploitation  of the
best optimizations we can find, when we would seek only to minimize performance.

The    effectiveness   of    search    heuristics   on    autotuning   can    be
limited\nbsp{}\cite{seymour2008comparison,balaprakash2011can,balaprakash2012experimental},
between other factors, by underlying hypotheses  about the search space, such as
the  reachability of  the  global optimum  and the  smoothness  of search  space
surfaces, which  are frequently not  respected. The derivation  of relationships
between  parameters  and  performance  from search  heuristic  optimizations  is
greatly hindered,  if not rendered impossible,  by the biased way  these methods
explore  parameters.   Some  parametric  learning methods,  such  as  Design  of
Experiments,  are  not widely  applied  to  autotuning.  These  methods  perform
structured  parameter  exploration,  and  can  be used  to  build  and  validate
performance     models,     generating    transparent     and     cost-effective
optimizations\nbsp{}\cite{mametjanov2015autotuning,bruel2019autotuning}. Other methods
from   the  parametric   family   are   more  widely   used,   such  as   Bandit
Algorithms\nbsp{}\cite{xu2017parallel}.   Nonparametric  learning   methods,  such  as
Decision    Trees\nbsp{}\cite{balaprakash2016automomml}     and    Gaussian    Process
Regression\nbsp{}\cite{parsa2019pabo}, are able  to reduce model bias  greatly, at the
expense of increased prediction variance. Figure\nbsp{}\ref{fig:tree} categorizes some
autotuning  methods  according to  some  of  the  key hypotheses  and  branching
questions underlying each method.

During this  thesis I have  adapted and  studied the effectiveness  of different
search heuristics and statistical learning  methods on optimizing performance on
several autotuning domains.  During the beginning of my PhD at the University of
São Paulo (USP), I have published a paper on optimizing the configuration of the
CUDA compiler\nbsp{}\cite{bruel2017autotuning},  where we have  reached up to  4 times
performance improvement  in comparison with a  high-level compiler optimization.
In collaboration with researchers from  Hewlett Packard Enterprise (HPE) in Palo
Alto, I wrote a  paper on the autotuning of a  compiler for High-Level Synthesis
for FPGAs\nbsp{}\cite{bruel2017autotuninghls}, where we  have reached, on average, 25%
improvements on  performance, size, and  complexity of  designs.

At the  end of 2017,  I joined  the /cotutelle/ PhD  program at the  University of
Grenoble Alpes  (UGA) and  became a member  of the POLARIS  Inria team,  where I
applied  Design  of   Experiments  to  the  autotuning   of  a  source-to-source
transformation  compiler\nbsp{}\cite{bruel2019autotuning},  where  we  showed  we  can
achieve significant speedup by exploiting  search space structure using a strict
budget.   I also  have  collaborated with  HPE on  another  paper, providing  an
analysis  of the  applicability  of autotuning  methods  to a  Hardware-Software
Co-design  problem\nbsp{}\cite{bruel2017generalize}.   During  my  Teaching  Assistant
internships,  I  have  published one  paper\nbsp{}\cite{bruel2017openmp}  on  parallel
programming  teaching, and  collaborated on  another\nbsp{}\cite{goncalves2016openmp},
where we showed that teaching lower level programming models, despite being more
challenging at first, provides a stronger core understanding.

I continue to collaborate with HPE  researchers on the application of autotuning
methods to  optimize Neural Networks,  hardware accelerators for  Deep Learning,
and  algorithms  for dealing  with  network  congestion.   With my  advisors,  I
currently manage  1 undergraduate and 4  masters students, who are  applying the
statistical  learning autotuning  methods  I studied  and  adapted to  different
domains  in the  context of  a joint  USP/HPE research  project.  I  am strongly
motivated to continue pursuing a career  on Computer Science research, aiming to
produce  rigorous and  value-adding  contributions. I  hereby  submit my  thesis
proposal and application to the Microsoft Latin America PhD Award.
#+begin_export latex
\begin{center}
  \begin{figure}[t]
    \resizebox{.9\textwidth}{!}{%
      \begin{forest}
        for tree={%
          anchor = north,
          align = center,
          l sep+=1em
        },
        [{Minimize $f: \mathcal{X} \mapsto \mathbb{R}$,\\$Y = f(X = (x_1,\dots,x_k) \in \mathcal{X}) + \varepsilon$},
          draw,
          [{Constructs surrogate estimate $\hat{f}(\cdot, \theta(X))$?},
            draw,
            color = NavyBlue
            [{Search Heuristics},
              draw,
              color = BurntOrange,
              edge label = {node[midway, fill=white, font = \scriptsize]{No}}
              [{\textbf{Random} \textbf{Sampling}}, draw]
              [{Reachable Optima},
                draw,
                color = BurntOrange
                [, phantom]
                [{Underlying Hypotheses \\ \textbf{Heuristics}}, draw]]]
            [{Statistical Learning},
              draw,
              color = BurntOrange,
              edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
              [{Parametric Learning},
                draw,
                color = BurntOrange
                [{$\forall{}i: x_i \in X$ is discrete\\$\hat{f}(X) \approx f_1(x_1) + \dots + f_k(x_k)$},
                  draw,
                  color = BurntOrange
                  [{\textbf{Independent Bandits}\\for each $x_i$:\textbf{UCB},\textbf{EXP3},$\dots$}, draw]
                  [, phantom]]
                [{Linear Model\\$\hat{f} = \mathcal{M}(X)\theta{}(X) + \varepsilon$},
                  draw,
                  color = BurntOrange
                  [, phantom]
                  [{Check for model adequacy?},
                    draw,
                    alias = adequacy,
                    color = NavyBlue
                    [{Consider interactions?\\{$\exists x_i \neq x_j:\; \theta(x_ix_j) \neq 0$}},
                      draw,
                      alias = interactions,
                      color = NavyBlue,
                      edge label = {node[midway, fill=white, font = \scriptsize]{No}}
                      [{$\forall x_i \in X: x_i \in \{-1, 1\}$\\\textbf{Screening} \textbf{Designs}},
                        edge label = {node[midway, fill=white, font = \scriptsize]{No}},
                        draw
                        [, phantom]
                        [{Select $\hat{X}_{*}$, reduce dimension of $\mathcal{X}$},
                          edge = {-stealth, ForestGreen, semithick},
                          edge label = {node[midway, fill=white, font = \scriptsize]{Exploit}},
                          draw,
                          alias = estimate,
                          color = ForestGreen]]
                      [{\textbf{Optimal} \textbf{Design}},
                        draw,
                        alias = optimal,
                        edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}]]
                    [, phantom]
                    [, phantom]
                    [, phantom]
                    [, phantom]
                    [, phantom]
                    [, phantom]
                    [{\textbf{Space-filling} \textbf{Designs}},
                      draw,
                      edge label = {node[midway, fill=white, font = \scriptsize]{Yes}}
                      [, phantom]
                      [{Model selection},
                        edge = {-stealth, ForestGreen, semithick},
                        edge label = {node[midway, fill=white, font = \scriptsize]{Explore}},
                        draw,
                        alias = selection,
                        color = ForestGreen]]]]]
              [{Nonparametric Learning},
                draw,
                color = BurntOrange
                [{Splitting rules on X\\\textbf{Decision} \textbf{Trees}},
                  draw
                  [, phantom]
                  [{Estimate $\hat{f}(\cdot)$ and $uncertainty(\hat{f}(\cdot))$},
                    edge = {-stealth, ForestGreen, semithick},
                    draw,
                    alias = uncertainty,
                    color = ForestGreen
                    [{Minimize $uncertainty(\hat{f}(X))$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Explore}},
                      draw,
                      color = ForestGreen]
                    [{Minimize $\hat{f}(X)$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Exploit}},
                      draw,
                      color = ForestGreen]
                    [{Minimize $\hat{f}(X) - uncertainty(\hat{f}(X))$},
                      edge = {ForestGreen, semithick},
                      edge label = {node[midway, fill=white, font = \scriptsize]{Exploit$+$Explore}},
                      draw,
                      color = ForestGreen]]]
                [{\textbf{Gaussian} \textbf{Process Regression}},
                  alias = gaussian,
                  draw]
                [{\textbf{Neural} \textbf{Networks}}, draw]]]]]
        \draw [-stealth, semithick, ForestGreen](selection) to [bend left=27] node[near start, fill=white, font = \scriptsize] {Exploit} (adequacy.south);
        \draw [-stealth, semithick, ForestGreen](estimate.east) to [bend right=37] node[near start, fill=white, font = \scriptsize] {Explore} (adequacy.south) ;
        \draw [-stealth, semithick, ForestGreen](gaussian) to (uncertainty);
        \draw [-stealth, semithick, ForestGreen](optimal) to node[midway, fill=white, font = \scriptsize] {Exploit} (estimate) ;
      \end{forest}
    }
    \caption{A high-level view of autotuning methods, where \textcolor{NavyBlue}{\textbf{blue}} boxes
      denote branching questions, \textcolor{BurntOrange}{\textbf{orange}} boxes
      denote key hypotheses, \textcolor{ForestGreen}{\textbf{green}} boxes
      highlight exploration and exploitation choices, and \textbf{bold} boxes denote methods.}
    \label{fig:tree}
  \end{figure}
\end{center}
#+end_export

#+latex: \newpage

#+LATEX: \bibliographystyle{IEEEtran}
#+LATEX: \bibliography{references}
*** (Short) Search Heuristics and Statistical Learning methods for Autotuning HPC Programs
:PROPERTIES:
:EXPORT_DATE:
:EXPORT_TITLE: @@latex: Search Heuristics and Statistical Learning \\ Methods for Program Autotuning@@
:EXPORT_FILE_NAME: short-application.pdf
:EXPORT_AUTHOR: Pedro Bruel
:END:

#+latex: \vspace{-3em}

High Performance Computing  has been a cornerstone of  collective scientific and
industrial progress  for at least  five decades.   Paying the cost  of increased
complexity,  software and  hardware  engineering advances  continue to  overcome
several challenges on the way of the sustained performance improvements observed
during the last  fifty years.  This mounting complexity means  that reaching the
advertised hardware  performance for  a given program  requires not  only expert
knowledge  of a  given hardware  architecture, but  also mastery  of programming
models  and  languages for  parallel  and  distributed  computing.

If we state performance optimization problems as /search/ or /learning/ problems, by
converting implementation  and configuration  choices to /parameters/  which might
affect  performance,  we  can  draw   and  adapt  proven  methods  from  search,
mathematical  optimization and  statistics. The  effectiveness of  these adapted
methods  on autotuning  problems varies  greatly,  and hinges  on practical  and
mathematical properties of the problem and the corresponding /search space/.

When  adapting methods  for autotuning,  we must  face challenges  emerging from
practical properties  such as restricted  time and cost budgets,  constraints on
feasible  parameter values,  and the  need to  mix /categorical/,  /continuous/, and
/discrete/ parameters. To achieve useful results, we must also choose methods that
make hypotheses compatible with problem search  spaces, such as the existence of
discoverable,  or at  least  exploitable, relationships  between parameters  and
performance.   Choosing  an autotuning  method  requires  determining a  balance
between the exploration of a problem, when we would seek to discover and explain
relationships between  parameters and performance,  and the exploitation  of the
best optimizations we can find, when we would seek only to minimize performance.

During this  thesis I have  adapted and  studied the effectiveness  of different
search heuristics and statistical learning  methods on optimizing performance on
several autotuning domains.  During the beginning of my PhD at the University of
São Paulo (USP), I have published a paper on optimizing the configuration of the
CUDA compiler\nbsp{}\cite{bruel2017autotuning},  where we have  reached up to  4 times
performance improvement  in comparison with a  high-level compiler optimization.
In collaboration with researchers from  Hewlett Packard Enterprise (HPE) in Palo
Alto, I wrote a  paper on the autotuning of a  compiler for High-Level Synthesis
for FPGAs\nbsp{}\cite{bruel2017autotuninghls}, where we  have reached, on average, 25%
improvements on  performance, size, and  complexity of  designs.

At the  end of 2017,  I joined  the /cotutelle/ PhD  program at the  University of
Grenoble Alpes  (UGA) and  became a member  of the POLARIS  Inria team,  where I
applied  Design  of   Experiments  to  the  autotuning   of  a  source-to-source
transformation  compiler\nbsp{}\cite{bruel2019autotuning},  where  we  showed  we  can
achieve significant speedup by exploiting  search space structure using a strict
budget.   I also  have  collaborated with  HPE on  another  paper, providing  an
analysis  of the  applicability  of autotuning  methods  to a  Hardware-Software
Co-design  problem\nbsp{}\cite{bruel2017generalize}.

I continue to collaborate with HPE  researchers on the application of autotuning
methods to  optimize Neural Networks,  hardware accelerators for  Deep Learning,
and  algorithms  for dealing  with  network  congestion.   With my  advisors,  I
currently manage  1 undergraduate and 4  masters students, who are  applying the
statistical  learning autotuning  methods  I studied  and  adapted to  different
domains  in the  context of  a joint  USP/HPE research  project.  I  am strongly
motivated to continue pursuing a career  on Computer Science research, aiming to
produce  rigorous and  value-adding  contributions. I  hereby  submit my  thesis
proposal and application to the Microsoft Latin America PhD Award.

#+LATEX: \bibliographystyle{IEEEtran}
#+LATEX: \bibliography{references}
* The Need for Autotuning in High Performance Computing
** Generating Figures                                             :noexport:
#+begin_SRC R :results output :session *R* :eval no-export :exports results
library(dplyr)
df_freq <- read.csv("data/wiki_data/frequency.csv", header = TRUE)
df_transistor <- read.csv("data/wiki_data/transistor_count.csv", header = TRUE)
#+end_SRC

#+RESULTS:

#+begin_SRC R :results output :session *R* :eval no-export :exports results
str(df_freq)
#+end_SRC

#+RESULTS:
#+begin_example
'data.frame':	199 obs. of  12 variables:
 $ date               : int  1971 1972 1972 1972 1972 1973 1973 1973 1974 1974 ...
 $ name               : chr  "4004" "PPS-25" "μPD700" "8008" ...
 $ designer           : chr  "Intel" "Fairchild" "NEC" "Intel" ...
 $ max_clock_khz      : int  740 400 NA 500 200 NA NA NA 715 NA ...
 $ max_clock_mhz      : num  NA NA NA NA NA 2 1 1 NA 2 ...
 $ max_clock_ghz      : num  NA NA NA NA NA NA NA NA NA NA ...
 $ process_micro_m    : num  10 NA NA 10 NA 7.5 6 NA NA 6 ...
 $ process_nm         : int  NA NA NA NA NA NA NA NA NA NA ...
 $ chips              : int  1 2 1 1 1 1 1 1 3 1 ...
 $ transistor_count   : int  2250 NA NA 3500 NA 2500 2800 NA NA 6000 ...
 $ transistor_millions: num  NA NA NA NA NA NA NA NA NA NA ...
 $ logical_cores      : int  1 1 1 1 1 1 1 1 1 1 ...
#+end_example

#+begin_SRC R :results output :session *R* :eval no-export :exports results
str(df_transistor)
#+end_SRC

#+RESULTS:
: 'data.frame':	151 obs. of  6 variables:
:  $ name            : chr  "Intel 4004 " "Intel 8008 " "Toshiba TLCS-12 " "Intel 4040 " ...
:  $ transistor_count: num  2250 3500 11000 3000 4100 ...
:  $ date            : int  1971 1972 1973 1974 1974 1974 1974 1975 1976 1976 ...
:  $ designer        : chr  "Intel" "Intel" "Toshiba" "Intel" ...
:  $ process_nm      : int  10000 10000 6000 10000 6000 6000 8000 8000 5000 4000 ...
:  $ area_mm         : num  12 14 32 12 16 20 11 21 27 18 ...

#+begin_SRC R :results graphics output :session *R* :file "./img/49_years_processor_data.pdf" :width 10 :height 5 :eval no-export
library(ggplot2)

ggplot() +
    geom_point(data = df_freq,
               aes(x = date,
                   y = logical_cores,
                   color = "Logical Cores (Count)")) +
    geom_point(data = df_freq,
               aes(x = date,
                   y = max_clock_khz * 1e-3,
                   color = "Frequency (MHz)")) +
    geom_point(data = df_freq,
               aes(x = date,
                   y = max_clock_mhz,
                   color = "Frequency (MHz)")) +
    geom_point(data = df_freq,
               aes(x = date,
                   y = max_clock_ghz * 1e3,
                   color = "Frequency (MHz)")) +
    geom_point(data = df_freq,
               aes(x = date,
                   y = transistor_count * 1e-3,
                   color = "Transistors (Thousands)")) +
    geom_point(data = df_freq,
               aes(x = date,
                   y = transistor_count * 1e-3,
                   color = "Transistors (Thousands)")) +
    geom_point(data = df_freq,
               aes(x = date,
                   y = transistor_millions * 1e3,
                   color = "Transistors (Thousands)")) +
    geom_point(data = df_transistor,
               aes(x = date,
                   y = transistor_count * 1e-3,
                   color = "Transistors (Thousands)")) +
    xlab("Year") +
    scale_color_brewer(name = element_blank(), palette = "Set1") +
    scale_y_continuous(trans = 'log10') +
    theme_bw(base_size = 18) +
    theme(axis.title.y = element_blank(),
          legend.position = c(0.14, 0.8),
          legend.direction = "horizontal",
          legend.background = element_rect(fill = "transparent", colour = NA),
          legend.text = element_text(size = 14)) +
    guides(color = guide_legend(nrow = 4,
                                override.aes = list(alpha = 1.0,
                                                    size = 2)))

#+end_SRC

#+RESULTS:
[[file:./img/49_years_processor_data.pdf]]

** Complexity on Hardware and Software
High Performance Computing  has been a cornerstone of  collective scientific and
industrial progress for at least five  decades.  By paying the cost of increased
complexity,  software and  hardware  engineering advances  continue to  overcome
several challenges on the way of the sustained performance improvements observed
during the last fifty years.  A  consequence of this mounting complexity is that
reaching the  advertised hardware performance  for a given program  requires not
only expert  knowledge of specific  hardware architectures, but also  mastery of
programming models and languages for parallel and distributed computing.

If we state performance optimization problems as /search/ or /learning/ problems, by
converting implementation  and configuration  choices to /parameters/  which might
affect  performance,  we  can  draw   and  adapt  proven  methods  from  search,
mathematical  optimization and  statistics. The  effectiveness of  these adapted
methods  on autotuning  problems varies  greatly,  and hinges  on practical  and
mathematical properties of the problem and the corresponding /search space/.

When  adapting methods  for autotuning,  we must  face challenges  emerging from
practical properties  such as restricted  time and cost budgets,  constraints on
feasible  parameter values,  and the  need to  mix /categorical/,  /continuous/, and
/discrete/ parameters. To achieve useful results, we must also choose methods that
make hypotheses compatible with problem search  spaces, such as the existence of
discoverable,  or at  least  exploitable, relationships  between parameters  and
performance.   Choosing  an autotuning  method  requires  determining a  balance
between the exploration of a problem, when we would seek to discover and explain
relationships between  parameters and performance,  and the exploitation  of the
best optimizations we can find, when we would seek only to minimize performance.

This  chapter presents  historical context  for  the increase  in complexity  of
computer  hardware  and  software, which  is  in  great  part  a result  of  the
strategies   used   to   sustain   the   unrelenting   pursuit   of   transistor
miniaturization,  supported  until  recently by  performance  improvements  from
frequency scaling.
** Backup Text                                                    :noexport:
The    effectiveness   of    search    heuristics   on    autotuning   can    be
limited\nbsp{}\cite{seymour2008comparison,balaprakash2011can,balaprakash2012experimental},
between other factors, by underlying hypotheses  about the search space, such as
the  reachability of  the  global optimum  and the  smoothness  of search  space
surfaces, which  are frequently not  respected. The derivation  of relationships
between  parameters  and  performance  from search  heuristic  optimizations  is
greatly hindered,  if not rendered impossible,  by the biased way  these methods
explore  parameters.   Some  parametric  learning methods,  such  as  Design  of
Experiments,  are  not widely  applied  to  autotuning.  These  methods  perform
structured  parameter  exploration,  and  can  be used  to  build  and  validate
performance     models,     generating    transparent     and     cost-effective
optimizations\nbsp{}\cite{mametjanov2015autotuning,bruel2019autotuning}. Other methods
from   the  parametric   family   are   more  widely   used,   such  as   Bandit
Algorithms\nbsp{}\cite{xu2017parallel}.   Nonparametric  learning   methods,  such  as
Decision    Trees\nbsp{}\cite{balaprakash2016automomml}     and    Gaussian    Process
Regression\nbsp{}\cite{parsa2019pabo}, are able  to reduce model bias  greatly, at the
expense of increased prediction variance. Figure\nbsp{}\ref{fig:tree} categorizes some
autotuning  methods  according to  some  of  the  key hypotheses  and  branching
questions underlying each method.

** References

#+LATEX: \bibliographystyle{IEEEtran}
#+LATEX: \bibliography{references}
